import os
import io
import uuid
import json
import time
import logging
import zipfile 
import argparse 
from pathlib import Path
from datetime import datetime
from pydantic import BaseModel 
from typing import List, Optional
from contextlib import asynccontextmanager  # å®šä¹‰FastAPIçš„ç”Ÿå‘½å‘¨æœŸ
from fastapi import FastAPI, HTTPException
from fastapi.staticfiles import StaticFiles
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import StreamingResponse, RedirectResponse


# Import the previously created RAG system
import sys
sys.path.append('.')
from rag_system import MultiModelRAGSystem

# Global variables SOS
rag_system: Optional[MultiModelRAGSystem] = None
force_rebuild_index = False  # Whether to force rebuild index
model_type = "gpt-4o"  # Default model type


# Conversation history saving function
def save_conversation_history(conversation_id: str, user_message: str, assistant_response: str, folder_name: Optional[str] = None):
    """Save conversation history to JSON file"""
    try:
        conversations_dir = Path("./conversations")
        conversations_dir.mkdir(exist_ok=True)
        
        conversation_file = conversations_dir / f"{conversation_id}.json"
        
        # Read existing conversation history
        if conversation_file.exists():
            with open(conversation_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = {
                "conversation_id": conversation_id,
                "created_at": datetime.now().isoformat(),
                "messages": []
            }
        
        # Add new conversation record
        history["messages"].append({
            "timestamp": datetime.now().isoformat(),
            "user_message": user_message,
            "assistant_response": assistant_response,
            "folder_name": folder_name
        })
        
        history["updated_at"] = datetime.now().isoformat()
        
        # Save to file
        with open(conversation_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
            
        logger.info(f"Conversation History Saved with ID: {conversation_id}.")
        
    except Exception as e:
        logger.error(f"Failed to Save Conversation History: {e}.")

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# @asynccontextmanager FastAPIåœ¨ç”Ÿå‘½å‘¨æœŸé‡Œç”¨å®ƒ
# FastAPI ä¼šåœ¨å¯åŠ¨ / å…³é—­æ—¶è°ƒç”¨å®ƒ; å‚æ•°appæ˜¯FastAPI å®ä¾‹
@asynccontextmanager
async def lifespan(app: FastAPI):  # å®šä¹‰ç”Ÿå‘½å‘¨æœŸç®¡ç†å‡½æ•° FastAPIä¼šè‡ªåŠ¨åœ¨å¯åŠ¨æ—¶è¿›å…¥ å…³é—­æ—¶é€€å‡º
    global rag_system, force_rebuild_index, model_type
    
    # Initialize RAG system on startup
    try:
        # Get corresponding API key based on model type
        if model_type in ["deepseek-chat", "deepseek-reasoner"]:
            api_key = os.getenv("DEEPSEEK_API_KEY")
            if not api_key:
                logger.error("DEEPSEEK_API_KEY Not Found. Please Set it As an Environment Variable.")
                yield  # ï¼ˆè®©æœåŠ¡èƒ½èµ·æ¥ï¼Œä½†ä¸åšåé¢çš„åˆå§‹åŒ–ï¼‰
                return
        else:
            api_key = os.getenv("OPENAI_API_KEY")
            if not api_key:
                logger.error("OPENAI_API_KEY Not Found. Please Set it As an Environment Variable.")
                yield  # è¿è¡Œç¨³å®šæ€§/å®¹é”™ä¸Šçš„å®‰å…¨æŠ¤æ â€ï¼ˆä¼˜é›…é™çº§ï¼‰
                return
        
        # Create necessary directories
        Path("./documents").mkdir(exist_ok=True)
        Path("./storage").mkdir(exist_ok=True)
        
        # Initialize RAG system
        rag_system = MultiModelRAGSystem(
            api_key=api_key,
            model_type=model_type,
            documents_dir="./documents",
            storage_dir="./storage"
        )
        
        # Track total rebuild time if force rebuilding
        if force_rebuild_index:  # å¦‚æœå‘½ä»¤è¡Œå‚æ•°æˆ–ç¯å¢ƒè¦æ±‚**å¼ºåˆ¶**é‡å»ºç´¢å¼• è®°å½•å¼€å§‹æ—¶é—´ å¹¶æ‰“å°æ—¥å¿—æé†’
            logger.info("ğŸš€ Start Rebuild Index...")
            t_start = time.time()
            documents = rag_system.load_documents()
            t_end = time.time()
            load_time = t_end - t_start
            logger.info(f"CHECK------Global Documents Loaded. Time used: {load_time:.2f}s")
            if documents:
                logger.info("ğŸš€ Start Rebuild Global Chat Engine Index...")
                rag_system.build_index(documents, force_rebuild=True)
                rag_system.create_chat_engine()
                logger.info(f"Global Chat Engine Index Built Successfully with {len(documents)} Document Pages.")
            else:
                logger.info(f"No Document Found for Global Chat Engine Index.")
            
            try:
                logger.info("ğŸš€ Start Rebuild Folder Index for Expert Chat Engine...")
                rag_system.build_folder_indexes(force_rebuild=force_rebuild_index)
                folders = rag_system.get_available_folders()
                if folders:
                    logger.info(f"Folder Index Built Successfully for Expert Chat Engine from Folders: {folders}.")
                else:
                    logger.info(f"No Folder Found for Expert Chat Engine Index.")
            except Exception as e:
                logger.error(f"Failed to Rebuild Folder Index for Expert Chat Engine: {e}.")
        
        else:   # é€šå¸¸åœ¨RAGç³»ç»Ÿé‡Œ ä¼šæœ‰ä¸¤ç§æ¨¡å¼
                # é‡å»ºç´¢å¼• (ä¼ æ–‡æ¡£ + force_rebuild=True): æŠŠæ‰€æœ‰æ–‡æ¡£é‡æ–°è¯»ä¸€é ç”Ÿæˆæ–°çš„ç´¢å¼• è¦†ç›–åŸæœ‰
                # åŠ è½½å·²æœ‰ç´¢å¼• (ä¼ ç©ºæ–‡æ¡£ + force_rebuild=False): åªæ£€æŸ¥æœ¬åœ°æœ‰æ²¡æœ‰å·²ç»ä¿å­˜çš„ç´¢å¼•æ–‡ä»¶ ç›´æ¥åŠ è½½ ä¸åšé‡å»º
            logger.info("This Run Will Attempt to Load the Existing (Folder) Index to Create Global Chat Engine and Expert Chat Engine.")

            # Try to load existing index without loading documents
            try:
                rag_system.build_index([], force_rebuild=False)  ### ä¼ å…¥ç©ºåˆ—è¡¨å¹¶è®¾ç½®ä¸é‡å»ºï¼šè¡¨ç¤ºâ€œåªåŠ è½½ç£ç›˜ä¸Šçš„æ—§ç´¢å¼•â€
                if rag_system.index is not None:  # æ£€æŸ¥æ˜¯å¦æˆåŠŸåŠ è½½åˆ°äº†ç´¢å¼•å¯¹è±¡ã€‚
                    rag_system.create_chat_engine()  # æ ¹æ®å·²ç»åˆ›å»ºçš„indexæ„å»ºäº†chatå¯¹è¯å¼•æ“
                    logger.info("Global Chat Engine Created Successfully.")
                else:
                    logger.info("No Existing Index Found for Global Chat Engine.")
            except Exception as e:
                logger.error(f"Failed to Load Existing Index for Global Chat Engine: {e}.")
            
            try:
                rag_system.build_folder_indexes(force_rebuild=force_rebuild_index)  # åŠ è½½folder index
                folders = rag_system.get_available_folders()  # è·å–å·²åŠ è½½åˆ°çš„æ–‡ä»¶å¤¹åˆ—è¡¨
                if folders:
                    logger.info(f"Folder Index Loaded Successfully from Folders: {folders}.")
                else:
                    logger.info("No Folder Found for Expert Chat Engine.")
            except Exception as e:
                logger.error(f"Failed to Load Existing Folder Index for Expert Chat Engine: {e}.")
            
    except Exception as e:
        logger.error(f"System Startup Failed: {e}.")
    
    yield
    
    # Clean up resources on shutdown
    logger.info("Shutting Down System...")
    logger.info("Bye, See You Next Time!")
    if rag_system:
        # Add cleanup logic here, such as closing database connections
        pass
 

app = FastAPI(
    title="Chat System", 
    description="Conversational System for AM Based on RAG and LLMs",
    lifespan=lifespan
)

# CORS configuration
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Should be restricted to specific domains in production
    #  allow_origins=["http://localhost:3000", "https://yourfrontend.com"],  # åªå…è®¸è¿™ä¸¤ä¸ªåŸŸåçš„å‰ç«¯è®¿é—®
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Data models
class ChatMessage(BaseModel):
    message: str
    conversation_id: Optional[str] = None
    folder_name: Optional[str] = None

class ChatResponse(BaseModel):  
    response: str
    conversation_id: str
    timestamp: str

class DocumentInfo(BaseModel):
    filename: str
    file_size: int
    upload_time: str
    file_type: str

class FolderInfo(BaseModel):
    folder_name: str
    documents_count: int
    has_index: bool
    index_status: str  # Ready, Not built


@app.get("/api/documents", response_model=List[DocumentInfo])
async def get_documents():
    """Get document list"""
    global rag_system
    
    if not rag_system:
        raise HTTPException(status_code=404, detail="RAG System Not Found.")
    
    try:
        documents_dir = Path("./documents")  # Path å¯¹è±¡
        document_list = []
        
        # é€’å½’éå† documents æ–‡ä»¶å¤¹åŠå…¶æ‰€æœ‰å­ç›®å½• åŒ¹é…æ‰€æœ‰æ–‡ä»¶å’Œæ–‡ä»¶å¤¹
        for file_path in documents_dir.rglob("*"):  
            if file_path.is_file():  # è¿‡æ»¤æ‰ç›®å½• åªä¿ç•™æ–‡ä»¶è·¯å¾„
                # statæ˜¯Pythonæ ‡å‡†åº“pathlib.Pathå¯¹è±¡çš„æ–¹æ³•ä½œç”¨æ˜¯è·å–æ–‡ä»¶çš„å…ƒæ•°æ®
                stat = file_path.stat()  # è·å–æ–‡ä»¶çš„å…ƒæ•°æ®ï¼ˆå¤§å°ã€ä¿®æ”¹æ—¶é—´ç­‰ï¼‰
                # print(file_path)  # documents/Enhanced Table Data/Enhanced_Table_Data.html
                relative_path = file_path.relative_to(documents_dir)  # ç›¸å¯¹äº documents ç›®å½•çš„è·¯å¾„ æ¯”å¦‚ "folder1/file.txt"
                document_list.append(DocumentInfo(
                    filename=str(relative_path),  # "folder1/file.txt"
                    file_size=stat.st_size,  # æ–‡ä»¶å¤§å°ï¼ˆå­—èŠ‚ï¼‰
                    # st_mtime æ–‡ä»¶çš„æœ€åä¿®æ”¹æ—¶é—´
                    # datetime.fromtimestamp(stat.st_mtime) è½¬æˆä¸€ä¸ª datetime å¯¹è±¡
                    # .isoformat() æŠŠ datetime è½¬æˆ ISO 8601 æ ¼å¼çš„å­—ç¬¦ä¸²
                    upload_time=datetime.fromtimestamp(stat.st_mtime).isoformat(),
                    file_type=file_path.suffix  # æ–‡ä»¶æ‰©å±•åï¼Œæ¯”å¦‚ ".txt"
                ))
        
        return sorted(document_list, key=lambda x: x.upload_time, reverse=True)  # æ˜¯é™åºï¼ˆå¤§åˆ°å°ï¼‰ï¼ˆæœ€æ–°çš„æ–‡ä»¶æ’æœ€å‰é¢ï¼‰
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to Get Document List: {e}.")

@app.get("/api/folders", response_model=List[FolderInfo])
async def get_folders():
    """Get folder list and their status"""
    global rag_system

    if not rag_system:
        raise HTTPException(status_code=404, detail="RAG System Not Found.")
    
    try:
        folders_info = []
        # Get all subfolders
        documents_dir = Path("./documents")
        for item in documents_dir.iterdir():  # åªéå†ä¸€çº§å­é¡¹ï¼ˆä¸ä¼šé€’å½’ï¼‰ç›¸å½“äºåˆ—å‡º documents/ ç›®å½•ä¸‹ç›´æ¥çš„å­æ–‡ä»¶å¤¹/æ–‡ä»¶
            if item.is_dir():  # è¿‡æ»¤æ‰æ–‡ä»¶ åªä¿ç•™å­æ–‡ä»¶å¤¹ã€‚
                folder_name = item.name  # æ‹¿åˆ°æ–‡ä»¶å¤¹åç§°ï¼ˆä¸å«è·¯å¾„ï¼‰
                documents_count = rag_system.get_folder_documents_count(folder_name)  # å‘ä½ çš„ RAG ç³»ç»Ÿè¯¢é—®è¯¥æ–‡ä»¶å¤¹ä¸‹å·²çº³å…¥/ç®¡ç†çš„æ–‡æ¡£æ•°é‡
                has_index = folder_name in rag_system.folder_indexes  # åˆ¤æ–­è¯¥æ–‡ä»¶å¤¹å¯¹åº”çš„æ£€ç´¢ç´¢å¼•æ˜¯å¦å·²ç»å»ºç«‹

                folders_info.append(FolderInfo(
                    folder_name=folder_name,
                    documents_count=documents_count,
                    has_index=has_index,
                    index_status="Ready" if has_index else "Not built"
                ))

        return sorted(folders_info, key=lambda x: x.folder_name)  # é»˜è®¤ reverse=False å³å‡åº

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to Get Folder List: {e}.")

@app.post("/api/chat", response_model=ChatResponse)
async def chat_with_documents(chat_message: ChatMessage):
    """Chat with documents (supports specifying folder)"""
    global rag_system
    
    if not rag_system:
        raise HTTPException(status_code=404, detail="RAG System Not Found.")
    
    try:
        # Generate or use existing conversation ID
        conversation_id = chat_message.conversation_id or str(uuid.uuid4())
        
        # Choose different processing methods based on whether folder is specified
        if chat_message.folder_name:
            # Query by folder
            if chat_message.folder_name not in rag_system.folder_indexes:
                raise HTTPException(status_code=404, detail=f"Folder Index for Folder '{chat_message.folder_name}' Not Found.")
            start_folder_time = time.time()  ### è®°å½•å¼€å§‹æ—¶é—´
            response = rag_system.chat_with_folder(chat_message.folder_name, chat_message.message)
            end_folder_time = time.time() - start_folder_time  ### è®¡ç®—è€—æ—¶
            logger.info(f"Generating Response from {chat_message.folder_name} Folder Index Time: {end_folder_time:.3f} Seconds.")  # è¾“å‡ºæ—¥å¿—
            response_prefix = f"[Based on Folder: {chat_message.folder_name}] "
        else:  # å¦‚æœæ²¡æŒ‡å®šæ–‡ä»¶å¤¹ï¼ˆå…¨å±€æ£€ç´¢ï¼‰ï¼š
            # Global query
            if not rag_system.chat_engine:  # æ£€æŸ¥å…¨å±€chatå¼•æ“æ˜¯å¦å¯ç”¨
                raise HTTPException(status_code=404, detail="Global RAG system not ready, please ensure there are available documents in the document directory")
            start_general_time = time.time()
            response = rag_system.chat(chat_message.message)  # ç”¨å…¨å±€é—®ç­”è¿”å›ç»“æœ
            end_general_time = time.time() - start_general_time
            logger.info(f"Generating Response from Global Chat Engine Time: {end_general_time:.3f} Seconds.")
            response_prefix = "[Global Search] "  # è®¾ç½®å…¨å±€å‰ç¼€ã€‚
        
        # Save conversation history to file
        save_conversation_history(conversation_id, chat_message.message, response, chat_message.folder_name)
        
        return ChatResponse(
            response=response_prefix + response,
            conversation_id=conversation_id,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to Chat: {e}.")

@app.get("/api/download/all")
async def download_all_documents():
    """Download ZIP archive of all documents"""
    global rag_system
    
    if not rag_system:
        raise HTTPException(status_code=404, detail="RAG System Not Found.")
    
    try:
        documents_dir = Path("./documents")
        if not documents_dir.exists():
            raise HTTPException(status_code=404, detail="Document Directory Not Found.")
        
        # Create ZIP file in memory
        zip_buffer = io.BytesIO()  # åœ¨å†…å­˜é‡Œåˆ›å»ºä¸€ä¸ªäºŒè¿›åˆ¶ç¼“å†²åŒºï¼Œç­‰ä¼šå„¿æŠŠ ZIP å†…å®¹å†™è¿›æ¥ï¼ˆä¸è½ç£ç›˜ï¼‰
        
        # ç›®æ ‡æ–‡ä»¶å°±æ˜¯åˆšåˆšçš„ zip_buffer ä¹Ÿå°±æ˜¯åœ¨å†…å­˜é‡Œåˆ›å»ºè¿™ä¸ªzipåŒ…
        # æ–°å»ºä¸€ä¸ª ZIP æ–‡ä»¶å¯¹è±¡ æŠŠå®ƒçš„è¾“å‡ºæŒ‡å‘ zip_buffer å†™å…¥æ¨¡å¼ ä½¿ç”¨ DEFLATED å‹ç¼©
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            # Recursively add all files to ZIP
            for file_path in documents_dir.rglob("*"):
                if file_path.is_file():  # é€’å½’éå† documents ä¸‹çš„å…¨éƒ¨æ¡ç›®ï¼›åªå¤„ç†æ–‡ä»¶ï¼Œè·³è¿‡ç›®å½•
                    # Get path relative to documents directory
                    relative_path = file_path.relative_to(documents_dir)  # æ–‡ä»¶ç»“æ„
                    zip_file.write(file_path, relative_path)   #å†™è¿›å»
        
        zip_buffer.seek(0)  # å†™å®ŒåæŠŠå†…å­˜æŒ‡é’ˆå›åˆ°èµ·ç‚¹ï¼Œå‡†å¤‡ä»å¤´è¯»å–æ•´ä¸ª ZIP å†…å®¹
        # å¦‚æœä¸æ‹‰å›å¼€å¤´ æ­¤æ—¶æŒ‡é’ˆåœ¨â€œæ–‡ä»¶æœ«å°¾â€ ä½ ç”¨zip_buffer.read()å»è¯»å†…å®¹æ—¶ ä¼šä»€ä¹ˆéƒ½è¯»ä¸åˆ° å› ä¸ºä»å½“å‰ä½ç½®å¾€åå·²ç»æ²¡æœ‰å†…å®¹äº†
        
        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"documents_backup_{timestamp}.zip"
        
        # Return ZIP file stream
        # Content-Disposition: attachment å‘Šè¯‰æµè§ˆå™¨â€œæˆ‘æ˜¯ä¸ªé™„ä»¶ï¼ˆéœ€è¦ä¸‹è½½ï¼‰â€ ä¸è¦ç›´æ¥åœ¨æµè§ˆå™¨çª—å£é‡Œæ‰“å¼€ è€Œæ˜¯è®©ç”¨æˆ·â€œä¿å­˜åˆ°æœ¬åœ°â€
        return StreamingResponse(
            io.BytesIO(zip_buffer.read()),  # åªè¦æ‹¿åˆ°zipæ–‡ä»¶çš„ äºŒè¿›åˆ¶å†…å®¹ å°±å¯ä»¥æŠŠè¿™äº›å†…å®¹åŒ…åˆ° io.BytesIO(...) é‡Œ æ„é€ æˆä¸€ä¸ªâ€œå†…å­˜æ–‡ä»¶â€å¯¹è±¡
            media_type="application/zip",  # å‘Šè¯‰æµè§ˆå™¨â€œè¿™æ˜¯ä¸€ä¸ªzipæ–‡ä»¶â€ æµè§ˆå™¨ä¼šè‡ªåŠ¨å¼¹å‡ºä¸‹è½½çª—å£ã€‚
            headers={"Content-Disposition": f"attachment; filename={filename}"}
        )   # Content-Disposition: attachment; filename=... å‘Šè¯‰æµè§ˆå™¨ä¸‹è½½ä¸ºé™„ä»¶å¹¶å»ºè®®æ–‡ä»¶å
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to Download Resource File Zip: {e}.")

# Root path redirect to frontend
@app.get("/")
async def root():
    """Redirect root path to frontend interface"""
    return RedirectResponse(url="/static/index.html")

# å°±æ˜¯æŠŠæœ¬åœ°çš„ static/ æ–‡ä»¶å¤¹ï¼Œæ˜ å°„åˆ°ç½‘å€çš„ /static ä¸‹é¢ã€‚
app.mount("/static", StaticFiles(directory="static"), name="static")


if __name__ == "__main__":
    from dotenv import load_dotenv
    load_dotenv()
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="Conversational System for AM Based on RAG and LLM.")
    parser.add_argument("--model", choices=["deepseek-chat", "deepseek-reasoner", "gpt4o", "gpt4.1"], default="gpt4o")
    parser.add_argument("--rebuild-index", action="store_true", help="Force Rebuild Index on Startup (Even If Index Files Exist).")  # æŠŠå‘½ä»¤è¡Œå‚æ•°å˜æˆä¸€ä¸ªå¸ƒå°”å€¼ True/False å¼€å…³ å‘½ä»¤è¡Œæ²¡å‡ºç°è¿™ä¸ª å°±æ˜¯False
    parser.add_argument("--host", default="localhost", help="Server Host Address (Default: localhost).")
    parser.add_argument("--port", type=int, default=8000, help="Server Port (Default: 8000).")
    args = parser.parse_args()

    # Set global variables
    model_type = args.model
    force_rebuild_index = args.rebuild_index
    
    if args.rebuild_index:
        print("Notice: The Index Will Be Rebuilt During This Run (Due To --rebuild-index Flag).")

    print(f"FastAPI Server Root URL:       http://{args.host}:{args.port}")
    print(f"FastAPI API Documentation:     http://{args.host}:{args.port}/docs")
    print(f"Frontend Interface Entry:      http://{args.host}:{args.port}/static/index.html")

    
    import uvicorn  # ç”¨Uvicornå¯åŠ¨FastAPIé¡¹ç›® ç»‘å®šåˆšæ‰è®¾ç½®çš„ä¸»æœºIPå’Œç«¯å£
    uvicorn.run(
        app,
        host=args.host, 
        port=args.port, 
    )  # è®©ä½ çš„ FastAPI é¡¹ç›®å˜æˆä¸€ä¸ªå¯¹å¤–å¼€æ”¾çš„ HTTP API æœåŠ¡ ç›‘å¬æŒ‡å®šçš„ host å’Œ port æ˜¯åç«¯å¯åŠ¨ è®©å‰ç«¯ æ¯”å¦‚Vueå¯ä»¥é€šè¿‡ HTTP è¯·æ±‚è®¿é—®è¿™ä¸ªåç«¯
